{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "228a7ae9-e15f-4f98-bf26-aee31b4da2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nScript: build_sea_england_1.py\\nPurpose: Load all cleaned season files (valid_*.csv) and compile them into\\n         the master Sea_England_1.csv file with all available columns.\\n\\nOutput: C:/Users/mikek/One Drive New/OneDrive/Leviathan/Ocean/England_1/Sea_England_1.csv\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script: build_sea_england_1.py\n",
    "Purpose: Load all cleaned season files (valid_*.csv) and compile them into\n",
    "         the master Sea_England_1.csv file with all available columns.\n",
    "\n",
    "Output: C:/Users/mikek/One Drive New/OneDrive/Leviathan/Ocean/England_1/Sea_England_1.csv\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83c3025e-3d94-4184-9694-f37b21fff370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created folder: C:\\Users\\mikek\\One Drive New\\OneDrive\\Leviathan\\Ocean\\England_1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define the full Ocean structure under Leviathan\n",
    "ocean_root = Path(r\"C:\\Users\\mikek\\One Drive New\\OneDrive\\Leviathan\\Ocean\")\n",
    "england_folder = ocean_root / \"England_1\"\n",
    "\n",
    "# Create folders if they don't exist\n",
    "england_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"âœ… Created folder: {england_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9fb162f-08a3-4d81-aad8-b1257249fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\mikek\\One Drive New\\OneDrive\\Leviathan\\Ocean\\England_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e923a7f-ac6e-48dd-a1bb-930e7ca1de38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/9394/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n",
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/9495/E0.csv\n",
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/9596/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/9697/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/9798/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n",
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/9899/E0.csv\n",
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/9900/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/0001/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/0102/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/0203/E0.csv\n",
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/0304/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/0405/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/0506/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/0607/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/0708/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/0809/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/0910/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/1011/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/1112/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/1213/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/1314/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/1415/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/1516/E0.csv\n",
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/1617/E0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\2978631541.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/1718/E0.csv\n",
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/1819/E0.csv\n",
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/1920/E0.csv\n",
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/2021/E0.csv\n",
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/2122/E0.csv\n",
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/2223/E0.csv\n",
      "â¬‡ï¸ Downloading https://www.football-data.co.uk/mmz4281/2324/E0.csv\n",
      "\n",
      "âœ… Saved 11944 rows to Sea_England_1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "import csv\n",
    "\n",
    "# Define all seasons\n",
    "years = [ '9394', '9495', '9596', '9697', '9798', '9899', '9900', '0001',\n",
    "          '0102', '0203', '0304', '0405', '0506', '0607', '0708', '0809',\n",
    "          '0910', '1011', '1112', '1213', '1314', '1415', '1516', '1617',\n",
    "          '1718', '1819', '1920', '2021', '2122', '2223', '2324']\n",
    "\n",
    "div = 'E0'\n",
    "all_dfs = []\n",
    "errors = []\n",
    "\n",
    "def safe_read_csv(url):\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    lines = r.content.decode(\"ISO-8859-1\").splitlines()\n",
    "\n",
    "    header = next(csv.reader([lines[0]]))\n",
    "    expected_cols = len(header)\n",
    "\n",
    "    df = pd.read_csv(StringIO(\"\\n\".join(lines)), usecols=range(expected_cols))\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df\n",
    "\n",
    "# Process each season\n",
    "for y in years:\n",
    "    url = f\"https://www.football-data.co.uk/mmz4281/{y}/{div}.csv\"\n",
    "    print(f\"â¬‡ï¸ Downloading {url}\")\n",
    "    try:\n",
    "        df = safe_read_csv(url)\n",
    "\n",
    "        # Clean and parse dates\n",
    "        df.columns = df.columns.str.strip()\n",
    "        if 'Date' not in df.columns:\n",
    "            raise ValueError(\"Missing 'Date' column\")\n",
    "        df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n",
    "        df = df.dropna(subset=['Date'])\n",
    "\n",
    "        # Sort by date to find actual season year from last match\n",
    "        df = df.sort_values('Date')\n",
    "        season_year = df['Date'].iloc[-1].year\n",
    "\n",
    "        df['Season'] = str(season_year)\n",
    "        df['Season_Div'] = f\"{season_year}_{div}\"\n",
    "\n",
    "        all_dfs.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {url}: {e}\")\n",
    "        errors.append((y, str(e)))\n",
    "\n",
    "# Combine and save\n",
    "combined = pd.concat(all_dfs, ignore_index=True, sort=False)\n",
    "combined.to_csv(\"Sea_England_1.csv\", index=False)\n",
    "\n",
    "print(f\"\\nâœ… Saved {len(combined)} rows to Sea_England_1.csv\")\n",
    "\n",
    "if errors:\n",
    "    print(\"\\nâš ï¸ Issues with the following seasons:\")\n",
    "    for year, msg in errors:\n",
    "        print(f\"- {year}: {msg}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5017bf41-77be-499c-90c1-8457378d300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Match count per season:\n",
      "Season\n",
      "1994    462\n",
      "1995    462\n",
      "1996    380\n",
      "1997    380\n",
      "1998    380\n",
      "1999    380\n",
      "2000    380\n",
      "2001    380\n",
      "2002    380\n",
      "2003    380\n",
      "2004    380\n",
      "2005    380\n",
      "2006    380\n",
      "2007    380\n",
      "2008    380\n",
      "2009    380\n",
      "2010    380\n",
      "2011    380\n",
      "2012    380\n",
      "2013    380\n",
      "2014    380\n",
      "2015    380\n",
      "2016    380\n",
      "2017    380\n",
      "2018    380\n",
      "2019    380\n",
      "2020    380\n",
      "2021    380\n",
      "2022    380\n",
      "2023    380\n",
      "2024    380\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ’¾ Saved to season_row_counts.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_22808\\992469029.py:4: DtypeWarning: Columns (131) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"Sea_England_1\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the combined dataset\n",
    "df = pd.read_csv(\"Sea_England_1\")\n",
    "\n",
    "# Show unique seasons and counts\n",
    "season_counts = df['Season'].value_counts().sort_index()\n",
    "\n",
    "print(\"ðŸ“Š Match count per season:\")\n",
    "print(season_counts)\n",
    "\n",
    "# Save to CSV if needed\n",
    "season_counts.to_csv(\"season_row_counts.csv\", header=[\"MatchCount\"])\n",
    "print(\"\\nðŸ’¾ Saved to season_row_counts.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f3f01f4-898f-4358-9cb8-1345d819cfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikek\\AppData\\Local\\Temp\\ipykernel_28484\\2008620686.py:6: DtypeWarning: Columns (131) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(england_path / \"Sea_England_1.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Creature layers created and README files written.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to master Sea file\n",
    "england_path = Path(r\"C:\\Users\\mikek\\One Drive New\\OneDrive\\Leviathan\\Ocean\\England_1\")\n",
    "df = pd.read_csv(england_path / \"Sea_England_1.csv\")\n",
    "\n",
    "# Define ordered column blocks\n",
    "core_cols = ['Season', 'Div', 'Date', 'Season_Div', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']\n",
    "ht_cols = ['HTHG', 'HTAG', 'HTR']\n",
    "ref_cols = ['Referee', 'HS', 'AS', 'HST', 'AST', 'HC', 'AC', 'HF', 'AF']\n",
    "wh_cols = ['WHH', 'WHD', 'WHA', 'WHCH', 'WHCD', 'WHCA']\n",
    "vc_cols = ['VCH', 'VCD', 'VCA', 'VCCH', 'VCCD', 'VCCA']\n",
    "b365_cols = ['B365H', 'B365D', 'B365A', 'B365CH', 'B365CD', 'B365CA']\n",
    "ps_cols = ['PSH', 'PSD', 'PSA', 'PSCH', 'PSCD', 'PSCA', 'P>2.5', 'P<2.5', 'PC>2.5', 'PC<2.5', 'PAHH', 'PAHA', 'PCAHA']\n",
    "\n",
    "# Create each data layer file\n",
    "def write_layer(creature, cols):\n",
    "    selected = [c for c in cols if c in df.columns]\n",
    "    df[selected].to_csv(england_path / f\"{creature}_England_1.csv\", index=False)\n",
    "\n",
    "# Layers\n",
    "write_layer(\"Plankton\", core_cols)\n",
    "write_layer(\"Krill\", core_cols + ht_cols)\n",
    "write_layer(\"Squid\", core_cols + ht_cols + ref_cols)\n",
    "write_layer(\"Turtle\", core_cols + ht_cols + wh_cols + vc_cols + b365_cols)\n",
    "write_layer(\"Dolphin\", core_cols + ht_cols + wh_cols + vc_cols + b365_cols + ps_cols[:6])\n",
    "write_layer(\"Orca\", core_cols + ht_cols + wh_cols + vc_cols + b365_cols + ps_cols)\n",
    "pd.read_csv(england_path / \"Orca_England_1.csv\").to_csv(england_path / \"SpermWhale_England_1.csv\", index=False)\n",
    "\n",
    "# Ocean-level README (with emoji-safe encoding)\n",
    "(england_path.parent / \"README.md\").write_text(\"\"\"# ðŸŒŠ Ocean: The Leviathan Football Data Lake\n",
    "\n",
    "Each league (e.g., England_1) contains layered data files named after ocean creatures:\n",
    "\n",
    "- ðŸ¦  Plankton â€” Basic results\n",
    "- ðŸ¦ Krill â€” Adds halftime results\n",
    "- ðŸ¦‘ Squid â€” Adds referee/stats\n",
    "- ðŸ¢ Turtle â€” Adds WH/VC/B365 odds\n",
    "- ðŸ¬ Dolphin â€” Adds PS consensus odds\n",
    "- ðŸ‹ Orca â€” Adds totals, Asian lines, closing odds\n",
    "- ðŸ³ SpermWhale â€” Complete rows only (same as Orca for now)\n",
    "\n",
    "Use the layer that best matches your modeling needs.\n",
    "\"\"\", encoding=\"utf-8\")\n",
    "\n",
    "# League-level README\n",
    "(england_path / \"README.md\").write_text(\"\"\"# ðŸ´ England_1 League Dataset\n",
    "\n",
    "This folder contains:\n",
    "- `Sea_England_1.csv`: Full dataset with all available columns\n",
    "- Layered files:\n",
    "  - `Plankton` â€” basic match results\n",
    "  - `Krill` â€” adds halftime results\n",
    "  - `Squid` â€” adds referee and match stats\n",
    "  - `Turtle` â€” adds WH/VC/Bet365 odds\n",
    "  - `Dolphin` â€” adds consensus + closing odds\n",
    "  - `Orca` â€” adds totals, Asian lines, more markets\n",
    "  - `SpermWhale` â€” currently same as Orca (will later filter to complete rows only)\n",
    "\"\"\", encoding=\"utf-8\")\n",
    "\n",
    "print(\"âœ… Creature layers created and README files written.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb94d841-d3be-498a-ace6-2edb1aa328b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
